{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from peptdeep.pretrained_models import ModelManager\n",
    "from peptdeep import settings\n",
    "from alphabase.psm_reader import psm_reader_provider\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sk\n",
    "import sklearn.linear_model as sk_lm\n",
    "import pickle\n",
    "\n",
    "%run alpha_pept_deep_methods.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df in max_quant format\n",
    "df = pd.read_csv(\"evidence_freshfrozen_base.txt\",  sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df with comparison of prediction to experimental values\n",
    "df_comp = pd.read_csv('prediction.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression CCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose category for which Linear Regression should be performed\n",
    "cat = 'CCS' # '1/K0'\n",
    "if cat == 'CCS':\n",
    "    pred = 'ccs_pred'\n",
    "else:\n",
    "    pred = 'IM_pred'\n",
    "n = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Training Set\n",
    "df_train = df_comp.sample(n=n,axis=0, random_state=42)\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "df_train_ab = mq_to_ab(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Linear Regression\n",
    "linear_reg = sk_lm.LinearRegression()\n",
    "linear_reg.fit(y = df_train[cat].values.reshape(-1,1), X = df_train[pred].values.reshape(-1,1))\n",
    "intercept = linear_reg.intercept_[0]\n",
    "slope = linear_reg.coef_[0][0]\n",
    "\n",
    "# Adjusted predictions\n",
    "df_train[f'{cat}_adj'] = intercept + slope * df_train[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 4.6\n",
    "print(intercept)\n",
    "print(slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Test Set, not overlapping with Training Set\n",
    "df_no_train = df_comp.drop(df_train.index)\n",
    "# sample for test set\n",
    "df_test = df_no_train.sample(n = n, axis=0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust Test Set\n",
    "df_test[f'{cat}_adj'] = intercept + slope * df_test[pred]\n",
    "df_test['adj_diff'] = np.subtract(df_test[cat].values, df_test[f'{cat}_adj'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error for Test Set\n",
    "print(df_test['adj_diff'].mean())\n",
    "print(df_test['adj_diff'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust Data\n",
    "df_comp[f'{cat}_adj'] = intercept + slope * df_comp[pred]\n",
    "df_comp['adj_diff'] = np.subtract(df_comp[cat].values, df_comp[f'{cat}_adj'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error after Linear Regression\n",
    "# Table 4.7\n",
    "print(df_comp['adj_diff'].mean())\n",
    "print(df_comp['adj_diff'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta95 after Linear Regression\n",
    "# Table 4.8\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "delta95 = percentiles(df_comp, 'adj_diff')\n",
    "print(f\"2.5 Percentile: {delta95[0]}, 97.5 Percentile: {delta95[1]}, Delta95: {delta95[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning (Random Training Set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Training Set\n",
    "n = 10000\n",
    "df_train = df.sample(n=n, axis=0,random_state=42)\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "df_train_ab = mq_to_ab(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "models = ModelManager(device = 'gpu')\n",
    "models.load_installed_models()\n",
    "models.train_ccs_model(df_train_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling Test Set, no Overlap with Training Set\n",
    "df_test = df.drop(df_train.index)\n",
    "df_test = df_test.sample(n = n, axis=0, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "df_test_ab = mq_to_ab(df_test)\n",
    "prediction_test = models.predict_mobility(df_test_ab)\n",
    "df_comp_test = ab_to_mq(df_test, prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error for Test Set\n",
    "cat = 'ccs' #'IM'\n",
    "print(df_comp_test[f'{cat}_error'].mean())\n",
    "print(df_comp_test[f'{cat}_error'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "df_ab = mq_to_ab(df)\n",
    "prediction = models.predict_mobility(df_ab)\n",
    "df_comp = ab_to_mq(df, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error after Transfer Learning\n",
    "# Table 4.9\n",
    "cat = 'ccs' #'IM'\n",
    "print(df_comp[f'{cat}_error'].mean())\n",
    "print(df_comp[f'{cat}_error'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta95 after Transfer Learning\n",
    "# Table 4.10\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "delta95 = percentiles(df_comp, f'{cat}_error')\n",
    "print(f\"2.5 Percentile: {delta95[0]}, 97.5 Percentile: {delta95[1]}, Delta95: {delta95[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error per Charge after Transfer Learning\n",
    "# Table 4.11\n",
    "cat = 'ccs' # 'IM'\n",
    "for charge in df_comp['Charge'].unique():\n",
    "    print(df_comp[df_comp['Charge']==charge][f'{cat}_error'].mean())\n",
    "    print(df_comp[df_comp['Charge']==charge][f'{cat}_error'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error over Biological Replicates \n",
    "# Table 4.15\n",
    "cat = 'ccs' # 'IM'\n",
    "df_51 = df_comp[df_comp[\"Experiment\"]=='P064051']\n",
    "print(len(df_51))\n",
    "print(df_51[f'{cat}_error'].mean())\n",
    "print(df_51[f'{cat}_error'].std())\n",
    "df_64 = df_comp[df_comp[\"Experiment\"]=='P064064']\n",
    "print(len(df_64))\n",
    "print(df_64[f'{cat}_error'].mean())\n",
    "print(df_64[f'{cat}_error'].std())\n",
    "df_28 = df_comp[df_comp[\"Experiment\"]=='P064428']\n",
    "print(len(df_28))\n",
    "print(df_28[f'{cat}_error'].mean())\n",
    "print(df_28[f'{cat}_error'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with Charge-balanced Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Training Set\n",
    "# discard Charge 1, because of too few measurements\n",
    "n = 10000\n",
    "\n",
    "df_2 = df[df['Charge']==2].sample(n = round(n/3), axis = 0, random_state =  42)\n",
    "df_3 = df[df['Charge']==3].sample(n = round(n/3), axis = 0, random_state = 42)\n",
    "df_4 = df[df['Charge']==4].sample(n= round(n/3), axis = 0, random_state = 42)\n",
    "\n",
    "df_train = pd.concat(objs=[df_2, df_3, df_4])\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "df_train_ab = mq_to_ab(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "models = ModelManager(device = 'gpu')\n",
    "models.load_installed_models()\n",
    "models.train_ccs_model(df_train_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta95 after Transfer Learning\n",
    "# Table 4.10\n",
    "cat = 'ccs' #'IM'\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "delta95 = percentiles(df_comp, f'{cat}_error')\n",
    "print(f\"2.5 Percentile: {delta95[0]}, 97.5 Percentile: {delta95[1]}, Delta95: {delta95[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict whole dataset\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "df_ab = mq_to_ab(df)\n",
    "prediction = models.predict_mobility(df_ab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = ab_to_mq(df, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error per Charge after Transfer Learning with charge-balanced Training Set\n",
    "# Table 4.12\n",
    "cat = 'ccs' # 'IM'\n",
    "for charge in df_comp['Charge'].unique():\n",
    "    print(df_comp[df_comp['Charge']==charge][f'{cat}_error'].mean())\n",
    "    print(df_comp[df_comp['Charge']==charge][f'{cat}_error'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error after Transfer Learning with charge-balanced Training Set\n",
    "# Table 4.13\n",
    "print(df_comp[f'{cat}_error'].mean())\n",
    "print(df_comp[f'{cat}_error'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta95 after Transfer Learning with charge-balanced Training Set\n",
    "# Table 4.14\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "delta95 = percentiles(df_comp, f'{cat}_error')\n",
    "print(f\"2.5 Percentile: {delta95[0]}, 97.5 Percentile: {delta95[1]}, Delta95: {delta95[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning (Biological Replicate-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split DAta into the 3 Biological Replicates\n",
    "df_51 = df[df[\"Experiment\"]=='P064051']\n",
    "df_64 = df[df[\"Experiment\"]=='P064064']\n",
    "df_28 = df[df[\"Experiment\"]=='P064428']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Biological Replicate\n",
    "df_ex = df_51 #P064051\n",
    "#df_ex = df_64 #P064064\n",
    "#df_ex = dF_28 #P064428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Training Set\n",
    "df_train = df.sample(n = round(0.2*len(df_ex)),axis=0, random_state=42)\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "df_train_ab = mq_to_ab(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "models = ModelManager(device = 'gpu')\n",
    "models.load_installed_models()\n",
    "models.train_ccs_model(df_train_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "df_ab = mq_to_ab(df_ex)\n",
    "prediction = models.predict_mobility(df_ab)\n",
    "df_comp = ab_to_mq(df_ex, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error for Biological Replicate\n",
    "# Table 4.16\n",
    "cat = 'ccs' #'IM'\n",
    "print(df_comp[f'{cat}_error'].mean())\n",
    "print(df_comp[f'{cat}_error'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta95 for Biological Replicate\n",
    "# Table 4.16\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "delta95 = percentiles(df_comp, f'{cat}_error')\n",
    "print(f\"2.5 Percentile: {delta95[0]}, 97.5 Percentile: {delta95[1]}, Delta95: {delta95[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean for all Biological Replicates\n",
    "# Table 4.15\n",
    "%run alpha_pept_deep_methods.ipynb\n",
    "df_ab = mq_to_ab(df)\n",
    "prediction = models.predict_mobility(df_ab)\n",
    "df_comp = ab_to_mq(df, prediction)\n",
    "\n",
    "for replicate in df_comp['Experiment'].unique():\n",
    "    df_exp = df_comp[df_comp['Experiment']==replicate]\n",
    "    print(df_exp[f'{cat}_error'].mean())\n",
    "    print(df_exp[f'{cat}_error'].std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning (Rawfile wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Transfer Learning per Rawfile\n",
    "result_dict = {}\n",
    "for experiment in df['Experiment'].unique():\n",
    "    print(experiment)\n",
    "    df_ex = df[df['Experiment']== experiment]\n",
    "    result_dict[experiment] = {}\n",
    "    # raw file wise\n",
    "    for raw_file in df_ex['Raw file']:\n",
    "        print(raw_file)\n",
    "        df_raw = df_ex[df_ex['Raw file']== raw_file]\n",
    "        df_ab = mq_to_ab(df_raw)\n",
    "        df_train = df_ab.sample(n = round(0.2*len(df_ab)), axis = 0, random_state = 42)\n",
    "        models = ModelManager(device = 'gpu')\n",
    "        models.load_installed_models()      \n",
    "        models.train_ccs_model(df_train)\n",
    "        prediction = models.predict_mobility(df_ab)\n",
    "        df_result = ab_to_mq(df_raw, prediction)\n",
    "        mean = df_result['ccs_error'].mean()\n",
    "        perc_low = np.percentile(df_result['ccs_error'], 2.5)\n",
    "        perc_up = np.percentile(df_result['ccs_error'], 97.5)\n",
    "        window = (perc_low)*(-1)+perc_up\n",
    "        result_dict[experiment][raw_file] = [mean, perc_low, perc_up, window]      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare Data for plotting\n",
    "result_51 = pd.DataFrame.from_dict(result_dict['P064051'])\n",
    "result_51 = result_51.T\n",
    "result_51.columns = ['Mean', 'Lower bound', 'Upper bound', 'Window']\n",
    "result_64 = pd.DataFrame.from_dict(result_dict['P064064'])\n",
    "result_64 = result_64.T\n",
    "result_64.columns = ['Mean', 'Lower bound', 'Upper bound', 'Window']\n",
    "result_28 = pd.DataFrame.from_dict(result_dict['P064428'])\n",
    "result_28 = result_28.T\n",
    "result_28.columns = ['Mean', 'Lower bound', 'Upper bound', 'Window']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Bar Plot: Delta95 per Rawfile\n",
    "# Figure 4.11\n",
    "result_dfs = [result_51, result_64, result_28]\n",
    "\n",
    "for df in result_dfs:\n",
    "    df['error_lower'] = df['Mean'] - df['Lower bound']\n",
    "    df['error_upper'] = df['Upper bound'] - df['Mean']\n",
    "\n",
    "    # Plot setup\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Plotting the error bars\n",
    "    plt.errorbar(x=range(len(df)), y=df['Mean'], \n",
    "                yerr=[df['error_lower'], df['error_upper']], \n",
    "                fmt='o', capsize=5, capthick=2,   elinewidth=2)#ecolor='gray',color='blue',\n",
    "    plt.scatter(x= range(len(df)), y=df['Mean'],  label='CCS prediction', zorder=5)\n",
    "    # Customize the plot\n",
    "    plt.xlabel('Fractions')\n",
    "    plt.ylabel('Delta 95 bounds')\n",
    "    plt.grid(False)\n",
    "    plt.hlines(y = 0.0, xmin = -1.5, xmax= 48.5, linestyles='--', colors='grey')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram: Delta95 per Biological Replicate for every Raw File\n",
    "# Figure 4.12\n",
    "result_51['Source'] = 'P064051'\n",
    "result_64['Source'] = 'P064064'\n",
    "result_28['Source'] = 'P064428'\n",
    "df_all = pd.concat([result_51, result_64, result_28],ignore_index=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(x=df_all['Window'],hue=df_all['Source'], multiple='dodge', palette='viridis', bins = 48)\n",
    "plt.xlabel('Window size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different training sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfile_sample = ['5471_P064051_R1_U23_GG9_1_2596', '5471_P064051_R1_U38_GF11_1_2611', '5471_P064051_R1_U13_GD8_1_2586']\n",
    "train_size = [0.20,0.30,0.40,0.50,0.60,0.70,0.80,0.90,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CCS Model with different Training Set Sizes\n",
    "for raw_file in rawfile_sample:\n",
    "    # set aside training set\n",
    "    df_raw_file = df[df['Raw file']==raw_file]    \n",
    "    test_set_mq = df_raw_file.sample(n = round(len(df_raw_file)*0.1), axis=0, random_state=42)\n",
    "    df_raw_file.drop(test_set_mq.index, inplace=True)\n",
    "    test_set = mq_to_ab(test_set_mq)\n",
    "    df_train_ab = mq_to_ab(df_raw_file)\n",
    "    result_dict = {}\n",
    "\n",
    "    # Train with every Training Set Size and predict all on the Test Set\n",
    "    for size in train_size:\n",
    "        df_train = df_train_ab.sample(n = round((size)*len(df_train_ab)),axis =0,  random_state=42)\n",
    "        models = ModelManager(device = 'gpu')\n",
    "        models.load_installed_models()      \n",
    "        models.train_ccs_model(df_train)\n",
    "        prediction = models.predict_mobility(test_set)\n",
    "        df_result = ab_to_mq(test_set_mq, prediction.copy())\n",
    "        mean = df_result['ccs_error'].mean()\n",
    "        delta95 = percentile(df_result, 'CCS')\n",
    "        result_dict[size] = [mean, delta95[0], delta95[1], delta95[2]]  \n",
    "    with open(f'train_size_eval/51_{raw_file}.pkl', 'wb') as f:\n",
    "        pickle.dump(result_dict, f)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare caluclated Data for Plotting\n",
    "with open('train_size_eval/51_5471_P064051_R1_U13_GD8_1_2586.pkl', 'rb') as f:\n",
    "    result_dict_1 = pickle.load(f)\n",
    "\n",
    "result_1 = pd.DataFrame.from_dict(result_dict_1)\n",
    "result_1 = result_1.T\n",
    "result_1.columns = ['Mean', 'Lower bound', 'Upper bound', 'Window']\n",
    "\n",
    "with open('train_size_eval/51_5471_P064051_R1_U23_GG9_1_2596.pkl', 'rb') as f:\n",
    "    result_dict_2 = pickle.load(f)\n",
    "\n",
    "result_2 = pd.DataFrame.from_dict(result_dict_2)\n",
    "result_2 = result_2.T\n",
    "result_2.columns = ['Mean', 'Lower bound', 'Upper bound', 'Window']\n",
    "\n",
    "with open('train_size_eval/51_5471_P064051_R1_U38_GF11_1_2611.pkl', 'rb') as f:\n",
    "    result_dict_3 = pickle.load(f)\n",
    "\n",
    "result_3 = pd.DataFrame.from_dict(result_dict_3)\n",
    "result_3 = result_3.T\n",
    "result_3.columns = ['Mean', 'Lower bound', 'Upper bound', 'Window']\n",
    "\n",
    "result_1['Source']='1_5471_P064051_R1_U13_GD8_1_2586'\n",
    "result_1['size'] = result_1.index\n",
    "result_2['Source']='51_5471_P064051_R1_U23_GG9_1_2596'\n",
    "result_2['size'] = result_2.index\n",
    "result_3['Source']='51_5471_P064051_R1_U38_GF11_1_2611'\n",
    "result_3['size'] = result_3.index\n",
    "df_merged = pd.concat(objs=[result_1, result_2, result_3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot: Delta95 per Training Set Size for every Rawfile\n",
    "# Figure 4.13\n",
    "g = sns.scatterplot(data=df_merged, x='size', y='Window', hue='Source', palette='viridis')\n",
    "plt.legend(title = 'Raw file', bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.xlabel('relative Training Set Size')\n",
    "plt.ylabel('âˆ†95')\n",
    "plt.figure(figsize=(16, 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
